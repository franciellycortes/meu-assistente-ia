import streamlit as st
import google.generativeai as genai
from PIL import Image
import io

# 1. CONFIGURA√á√ÉO DA P√ÅGINA
st.set_page_config(page_title="Mentor Neuropsicopedag√≥gico", page_icon="üß†", layout="wide")

# Estilo Visual
st.markdown("""
    <style>
    .stApp { background: linear-gradient(135deg, #e0f7fa 0%, #f3e5f5 50%, #fce4ec 100%); }
    [data-testid="stSidebar"] { background-color: #f1f8e9 !important; }
    .stChatMessage { border-radius: 15px; border: 1px solid #d1d9e6; background-color: white; }
    h1 { color: #4a148c; }
    </style>
    """, unsafe_allow_html=True)

# 2. PERSONALIDADE T√âCNICA
instrucao_sistema = """
Voc√™ √© um Mentor de Alto N√≠vel em Psicopedagogia Cl√≠nica, fundamentado na Epistemologia Convergente (Jorge Visca).
Sua an√°lise deve integrar Piaget, Vygotsky, Wallon e Alicia Fern√°ndez.

ESTRUTURA OBRIGAT√ìRIA DE RESPOSTA:
1. Eixo Cognitivo (Piaget/Neuro): Est√°gio e fun√ß√µes executivas.
2. Eixo Socioafetivo (Vygotsky/Wallon/Fern√°ndez): Media√ß√£o e v√≠nculo.
3. Eixo Instrumental (Sampaio/Visca): Sugest√£o de testes (EOCA, Provas Operat√≥rias).
4. Eixo Terap√™utico: Hip√≥teses e estrat√©gias pr√°ticas.
"""

# 3. CONEX√ÉO COM A API (EST√ÅVEL)
try:
    CHAVE_API = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=CHAVE_API)
    
    # Mudan√ßa para evitar o erro 404: usamos o modelo sem o prefixo v1beta
    model = genai.GenerativeModel(
        model_name='gemini-1.5-flash',
        system_instruction=instrucao_sistema
    )
except Exception as e:
    st.error(f"Erro na conex√£o: {e}")

# 4. GEST√ÉO DE MEM√ìRIA
if "chat_session" not in st.session_state:
    st.session_state.chat_session = model.start_chat(history=[])

# 5. BARRA LATERAL
with st.sidebar:
    st.title("üìÇ Painel Cl√≠nico")
    st.info("Modelo Est√°vel: Gemini 1.5 Flash")
    arquivo_upload = st.file_uploader("Subir Relat√≥rio ou Imagem", type=["png", "jpg", "jpeg", "pdf"])
    
    st.divider()
    if st.button("üóëÔ∏è Nova Supervis√£o"):
        st.session_state.chat_session = model.start_chat(history=[])
        st.rerun()

st.title("üß† Mentor Neuropsicopedag√≥gico")

# 6. HIST√ìRICO
for mensagem in st.session_state.chat_session.history:
    role = "user" if mensagem.role == "user" else "assistant"
    with st.chat_message(role):
        st.markdown(mensagem.parts[0].text)

# 7. INTERA√á√ÉO E PROCESSAMENTO
if prompt := st.chat_input("Descreva o caso cl√≠nico..."):
    with st.chat_message("user"):
        st.markdown(prompt)
    
    try:
        conteudo_envio = [prompt]
        
        if arquivo_upload:
            if arquivo_upload.type == "application/pdf":
                # Tratamento espec√≠fico para PDF enviado como documento
                conteudo_envio.append({
                    "mime_type": "application/pdf",
                    "data": arquivo_upload.getvalue()
                })
            else:
                img = Image.open(arquivo_upload)
                conteudo_envio.append(img)

        with st.spinner("Analisando eixos cl√≠nicos..."):
            # Envio for√ßando o uso do modelo configurado
            response = st.session_state.chat_session.send_message(conteudo_envio)
        
        with st.chat_message("assistant"):
            st.markdown(response.text)
            
    except Exception as e:
        if "404" in str(e):
            st.error("Erro 404: O sistema n√£o encontrou o modelo. Verifique se o arquivo 'requirements.txt' est√° atualizado no seu GitHub.")
        elif "429" in str(e):
            st.warning("Limite de cota atingido. Aguarde 60 segundos.")
        else:
            st.error(f"Erro no processamento: {e}")
